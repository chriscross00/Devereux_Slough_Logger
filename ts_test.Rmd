---
title: "ts_test"
author: "Christopher Chan"
date: "February 7, 2019"
output:
    github_document
---

Benchmark:
https://afit-r.github.io/ts_benchmarking

READ THIS: (Should fix seasonality)
https://robjhyndman.com/hyndsight/longseasonality/
https://robjhyndman.com/hyndsight/forecasting-weekly-data/
https://www.kaggle.com/kailex/arima-with-fourier-terms
https://s3.amazonaws.com/assets.datacamp.com/production/course_3002/slides/ch5.pdf

modeling in ggplot
https://robjhyndman.com/hyndsight/ftsviz/


https://otexts.com/fpp2/arima-r.html
https://stats.stackexchange.com/questions/286505/how-do-i-tell-that-my-time-series-is-stationary-or-not
https://stats.stackexchange.com/questions/137967/is-my-time-series-stationary


Seasonality:
https://stats.stackexchange.com/questions/245729/forecast-time-series-with-two-seasonal-patterns
https://stackoverflow.com/questions/23604432/daily-time-series-with-ts-how-to-specify-start-and-end



### Links:

https://datascienceplus.com/time-series-analysis-using-arima-model-in-r/
https://people.duke.edu/~rnau/411arim2.htm

https://www.r-bloggers.com/time-series-analysis-building-a-model-on-non-stationary-time-series/
https://otexts.com/fpp2/stationarity.html

https://ourcodingclub.github.io/2017/04/26/time.html



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(gridExtra)
library(here)
library(forecast)
```

Reading in a logger dataset that I've been using for testing.
```{r, results='hide', message=FALSE}
here()
lv <- read_csv('180301 Level Data copy.csv')

lv$date_time <- as.POSIXct(lv$date_time, format = '%m/%d/%y %H:%M')
```
msts 
```{r}
lv_ts_wk <- msts(lv$level_m, seasonal.periods=c(96,35064))

plot(lv_ts_wk)
```

The adf test shows that the raw ts is non-stationary. The differed(96) shows that there it is stationarity.
```{r}
test1_diff <- diff(lv_ts_wk, lag=96)

lv_ts_wk %>% adf.test(k=96)
test1_diff %>% adf.test(k=96)
```

<<<<<<< HEAD
msts
=======
diff lv_ts_wk
>>>>>>> 1feb3c5e693b2b5d2decc1b36be3d42998e7c39b
```{r}
ggAcf(test1_diff, lag.max=100)
ggPacf(test1_diff, lag.max=100)
```

arima with daily and annual seasonality
```{r}
auto_fit <- auto.arima(lv_ts_wk, seasonal=FALSE, xreg=fourier(lv_ts_wk, K=c(4,1)))
plot(forecast(auto_fit, h=192, xreg=fourier(lv_ts_wk, K=c(4,1), h=192)))
```



```{r}
auto_test1 <- auto.arima(test1_diff, seasonal=FALSE, xreg=fourier(test1_diff, K=4))
plot(forecast(auto_test1, h=192, xreg=fourier(test1_diff, K=4, h=192)))
```

```{r}
lv_ts <- ts(lv$level_m, f=96)


head(lv_ts)
plot(lv_ts)
```



Checking to make sure all the data points are in the zoo class. 
```{r}
lv_df <- lv[c(2,5)]

cat('Absolute difference in water level over the period of', as.character(start(lv_zoo)), 'and', as.character(end(lv_zoo)), 'in meters:', max(lv_df$level_m) - min(lv_df$level_m))
```

Graphing the water level across time we gather a number of important insights into our data. The first is that the time series is not stationary. A quick look at the graph and we can conclude that the mean decreases over time. Without further testing it is too hard to tell if the variance and covariance vary over time, but I believe they are relatively constant. If the variance is constant than we can perform additive decomposition, this is where the seasonal variation is constant across time. A additive model is describe as:
$Time series = Seasonal + Trend + Random$

Second, it appears we have some seasonality, on a daily basis. This should be removed in order to get a accurate depiction of the trend of the series. These statitistical facts fit the ecological realities of Devereux Slough. Because of the very short rainy season, roughly 3 months, in Santa Barbara we would expect to see water level decrease in late winter.

```{r, warning=FALSE}
ggplot(lv_df, aes(date_time, level_m)) +
    geom_line() +
    xlab('Date') +
    ylab('Level (m)') + 
    ggtitle('Water level (m) over time')
```

The same time series with a smoothing function to get the general trend.
```{r}
ggplot(lv_df, aes(date_time, level_m)) +
    geom_line() +
    geom_smooth(method = 'loess', se = FALSE) +
    xlab('Date') +
    ylab('Level (m)') + 
    ggtitle('Water level (m) over time w/ trend line')
```


TO DO: Write more
* What the graph shows
* Analysis

This checks the seasonality and trend of the data. The seasonality seems to be daily and the trend is a gradual downward slope. 
```{r}
ts <- ts(lv_df$level_m, frequency = 96)

decomp_ts <- stl(ts, s.window='period')
plot(decomp_ts)
```

ACF and PACF before differencing. There is a obvious pattern to our data and most of the ACF lags are above the significance level. This indicates we must difference the data, the question is by how much.
```{r}
grid.arrange(ggAcf(lv_zoo), ggPacf(lv_zoo), nrow=2)
```

A finer breakdown of the seasonally differenced level data.
```{r}
plot(lv_diff, type='l')
ggAcf(lv_diff, lag.max=200)
ggPacf(lv_diff, lag.max=200)
```

To make sure our data is stationary we'll run a augmented Dickey-Fuller test (ADF). ADF comes to a incorrect conclusion about our raw data. Visually the data is non-stationary, there is a obvious downward trend. We'll run a kpss test 

```{r}
# MA
ggAcf(diff(lv_diff), lag.max=100)
# AR
ggPacf(diff(lv_diff), lag.max=100)
```


Read to check the model:
https://stats.stackexchange.com/questions/286900/arima-forecast-straight-line
http://online.sfsu.edu/mbar/ECON312_files/Forecasting.html

https://stats.stackexchange.com/questions/65585/auto-arima-does-not-recognize-seasonal-pattern
https://robjhyndman.com/hyndsight/longseasonality/


```{r}
checkresiduals(model_diff)

forecast(model_diff, h=50)
```

Creation of a model from
```{r}
lv_zoo %>%
    Arima(order=c(2,1,3), seasonal=c(0,1,0)) %>%
    forecast(h=500) %>%
    autoplot()
```

```{r}
what <- lv_ts %>%
    arima(order=c(4,1,0), seasonal=list(order=c(0,1,1), period=96))
```

just testing a FT
```{r}
auto_fit <- auto.arima(lv_ts, seasonal=FALSE, xreg=fourier(lv_ts, K=1))
auto_fit
```
plot of auto_arima FT
```{r}
plot(forecast(auto_fit, h=192, xreg=fourier(auto_fit, K=1, h=192)))
grid(nx=20)
```


Running a Lijung-Box test to quantifiable determine if the ACF of lv_diff is non-zero. Because the $H_0$ of the Box-Ljung test is that the data is independently distributed, $H_1$ means that the data is not independently distributed and serial correlation exist. Since the p-value is less than standrd of 0.05, in this case it is less than 2.2e-16, we reject the $H_0$ and conclude the data has some serial correlation.
```{r}
Box.test(lv_diff, lag=10, type='Ljung-Box')
```


The classical additive decomposition:
$$X_{t} = \mu_{t} + s_{t} + Z_{t}$$

Where $\mu_{t}$ is the trend component, $s_{t}$ is the seasonal component, and $Z_{t}$ is the white noise. Goal is to make $Z_{t}$ stationary random so that we can  

Python links:

* https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/
* https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/



